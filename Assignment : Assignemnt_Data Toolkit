Assignment : Assignemnt_Data Toolkit
"1. What is NumPy, and why is it widely used in Python?",
     "Answer:\nNumPy (Numerical Python) is a fundamental library for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with mathematical functions to operate on these arrays.\n\nWhy NumPy is widely used:\n• Performance: NumPy arrays are faster and more efficient than Python lists (implemented in C)\n• Vectorized operations: Allows mathematical operations on entire arrays without explicit loops\n• Broadcasting: Enables operations on arrays of different shapes\n• Comprehensive mathematical functions: Linear algebra, Fourier transform, random number generation\n• Integration: Foundation for other libraries like Pandas, SciPy, scikit-learn, TensorFlow\n• Memory efficiency: Stores data in contiguous memory locations\n\nNumPy is the foundation of the Python scientific computing ecosystem."),
    
    ("2. How does broadcasting work in NumPy?",
     "Answer:\nBroadcasting is a powerful mechanism in NumPy that allows operations between arrays of different shapes. It eliminates the need for explicit loops and makes code more efficient and readable.\n\nHow broadcasting works:\n• The smaller array is 'broadcast' across the larger array to make their shapes compatible\n• Rules:\n  1. Starting from trailing dimensions, dimensions must be equal or one of them must be 1\n  2. If dimensions differ, arrays with size 1 in that dimension are stretched to match\n  3. If one array has fewer dimensions, it's padded with 1s on the left\n\nExample:\nimport numpy as np\na = np.array([1, 2, 3])      # Shape: (3,)\nb = 2                         # Scalar (0 dimensions)\nc = a * b                     # b is broadcast to shape (3,)\n# Result: [2, 4, 6]\n\nMore complex:\nmatrix = np.array([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\nvector = np.array([10, 20, 30])             # Shape: (3,)\nresult = matrix + vector  # Vector broadcast to (2, 3)"),
    
    ("3. What is a Pandas DataFrame?",
     "Answer:\nA Pandas DataFrame is a two-dimensional, labeled data structure with columns of potentially different types. It's similar to a spreadsheet, SQL table, or dictionary of Series objects.\n\nKey characteristics:\n• Tabular structure with rows and columns\n• Labeled axes (row indices and column names)\n• Heterogeneous data types across columns\n• Powerful data manipulation capabilities\n\nCreating DataFrames:\nimport pandas as pd\n\n# From dictionary\ndf1 = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n\n# From list of lists\ndf2 = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])\n\n# From CSV\ndf3 = pd.read_csv('data.csv')\n\nDataFrames are the core data structure in Pandas for data analysis."),
    
    ("4. Explain the use of the groupby() method in Pandas.",
     "Answer:\nThe groupby() method in Pandas is used to split data into groups based on some criteria, apply a function to each group independently, and combine the results. It follows the 'split-apply-combine' paradigm.\n\nCommon operations:\n• Split: Group data by one or more columns\n• Apply: Perform operations like sum, mean, count, custom functions\n• Combine: Merge results into a new DataFrame\n\nExample:\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Department': ['Sales', 'IT', 'Sales', 'IT', 'HR'],\n    'Employee': ['John', 'Alice', 'Bob', 'Charlie', 'Diana'],\n    'Salary': [50000, 60000, 55000, 65000, 45000]\n})\n\n# Group by department and calculate mean salary\ndept_mean = df.groupby('Department')['Salary'].mean()\n\n# Multiple aggregations\ndept_stats = df.groupby('Department').agg({\n    'Salary': ['mean', 'sum', 'count']\n})\n\nUseful for:\n• Summarizing data by categories\n• Performing statistical analysis by groups\n• Data aggregation and reporting"),
    
    ("5. Why is Seaborn preferred for statistical visualizations?",
     "Answer:\nSeaborn is preferred for statistical visualizations because:\n\n1. Built on Matplotlib: Provides high-level interface with better aesthetics\n2. Statistical focus: Specialized plots for statistical analysis (distributions, regression, etc.)\n3. Automatic aggregation: Handles statistical aggregation automatically\n4. Beautiful defaults: More attractive and publication-ready plots with minimal code\n5. Dataset-oriented: Works seamlessly with Pandas DataFrames\n6. Color palettes: Built-in color schemes for different data types\n7. Complex visualizations: Easy creation of complex plots like pairplots, heatmaps, violin plots\n8. Statistical estimation: Shows confidence intervals automatically\n\nExample:\nimport seaborn as sns\nsns.set_theme()  # Set beautiful defaults\nsns.histplot(data=df, x='column')  # Automatic binning and density estimation"),
    
    ("6. What are the differences between NumPy arrays and Python lists?",
     "Answer:\n| Feature | NumPy Arrays | Python Lists |\n|---------|--------------|--------------|\n| Homogeneity | All elements same data type | Can mix different types |\n| Performance | Fast (C implementation) | Slower (Python objects) |\n| Memory | Efficient, contiguous | More overhead per element |\n| Operations | Vectorized operations | Require explicit loops |\n| Functionality | Mathematical functions | General-purpose |\n| Broadcasting | Supported | Not supported |\n| Slicing | Returns view (fast) | Returns copy |\n| Dimensions | Multi-dimensional | One-dimensional primarily |\n| Indexing | Advanced (boolean, fancy) | Basic integer indexing |\n\nExample:\nimport numpy as np\n\n# NumPy array\narr = np.array([1, 2, 3, 4, 5])\narr_squared = arr ** 2  # Vectorized\n\n# Python list\nlst = [1, 2, 3, 4, 5]\nlst_squared = [x**2 for x in lst]  # List comprehension needed"),
    
    ("7. What is a heatmap, and when should it be used?",
     "Answer:\nA heatmap is a data visualization technique that represents data values using color intensity. It displays a matrix of values where each cell is colored based on its value.\n\nWhen to use heatmaps:\n• Correlation matrices: Show relationships between variables\n• Confusion matrices: Visualize classification results\n• Time series patterns: Display data over two dimensions (e.g., hours × days)\n• Geographic data: Show intensity across locations\n• Missing data: Visualize missing values patterns\n• Feature importance: Display importance scores across models\n\nExample with Seaborn:\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Correlation matrix\ncorrelation = df.corr()\nsns.heatmap(correlation, annot=True, cmap='coolwarm')\nplt.show()\n\nAdvantages:\n• Quick pattern recognition\n• Handle large matrices\n• Intuitive color encoding\n• Can display annotations"),
    
    ("8. What does the term 'vectorized operation' mean in NumPy?",
     "Answer:\nVectorized operations refer to performing operations on entire arrays without explicit loops. NumPy applies operations element-wise using optimized C code, making computations significantly faster than Python loops.\n\nExamples:\nimport numpy as np\n\narr = np.array([1, 2, 3, 4, 5])\n\n# Vectorized operations\nsquared = arr ** 2                 # Each element squared\ndoubled = arr * 2                  # Each element doubled\nsqrt_arr = np.sqrt(arr)            # Square root of each element\nsum_arr = np.sum(arr)              # Sum all elements\n\n# Conditional operations\nmask = arr > 3\nfiltered = arr[mask]               # Boolean indexing\n\n# Mathematical operations\nresult = np.sin(arr) + np.cos(arr) # Combined operations\n\nBenefits:\n• Speed: 10-100x faster than Python loops\n• Concise: Cleaner, more readable code\n• Less error-prone: Fewer opportunities for bugs\n• Memory efficient: Uses optimized algorithms"),
    
    ("9. How does Matplotlib differ from Plotly?",
     "Answer:\n| Feature | Matplotlib | Plotly |\n|---------|------------|--------|\n| Type | Static plots | Interactive plots |\n| Output | PNG, PDF, SVG (static) | HTML, JSON (interactive) |\n| Interactivity | Limited (zooming, panning) | Hover tooltips, zoom, pan, selection |\n| Web integration | Not native | Built for web apps |\n| Learning curve | Steeper | Moderate |\n| Customization | Highly customizable | Good customization |\n| 3D plots | Basic support | Excellent 3D support |\n| Dashboards | Not built-in | Integrated with Dash |\n| File size | Smaller | Larger (interactive features) |\n\nWhen to use:\n• Matplotlib: Publications, static reports, simple plots\n• Plotly: Web applications, interactive dashboards, exploratory analysis\n\nExample Matplotlib:\nimport matplotlib.pyplot as plt\nplt.plot(x, y)\nplt.savefig('plot.png')\n\nExample Plotly:\nimport plotly.express as px\nfig = px.scatter(df, x='x', y='y')\nfig.show()"),
    
    ("10. What is the significance of hierarchical indexing in Pandas?",
     "Answer:\nHierarchical indexing (MultiIndex) in Pandas allows working with higher-dimensional data in a 2D DataFrame structure. It enables creating multiple index levels on rows or columns.\n\nSignificance:\n• Represent higher-dimensional data in 2D\n• More sophisticated data selection and grouping\n• Partial indexing (selecting at one level)\n• Stack/unstack operations for reshaping\n• Better organization for complex data\n\nExample:\nimport pandas as pd\n\n# Create MultiIndex\nindex = pd.MultiIndex.from_tuples([\n    ('Group A', 2020), ('Group A', 2021),\n    ('Group B', 2020), ('Group B', 2021)\n], names=['Group', 'Year'])\n\ndf = pd.DataFrame({\n    'Revenue': [100, 110, 200, 210],\n    'Expenses': [80, 85, 150, 160]\n}, index=index)\n\n# Selection at different levels\ndf.loc['Group A']           # All years for Group A\ndf.xs(2020, level='Year')   # All groups in 2020\n\n# Unstack to create pivot\ndf.unstack(level='Year')"),
    
    ("11. What is the role of Seaborn's pairplot() function?",
     "Answer:\npairplot() creates a matrix of scatter plots showing pairwise relationships between variables in a dataset. It's used for exploratory data analysis to visualize patterns and correlations.\n\nFeatures:\n• Diagonal: Shows distribution of each variable (histograms/KDE)\n• Off-diagonal: Scatter plots of variable pairs\n• Hue parameter: Color points by categorical variable\n• Multiple plots: Automatically handles all variable combinations\n\nExample:\nimport seaborn as sns\n\n# Load sample data\ndf = sns.load_dataset('iris')\n\n# Create pairplot\nsns.pairplot(df, hue='species', diag_kind='hist')\n\nUses:\n• Identify correlations between variables\n• Spot patterns and clusters\n• Detect outliers\n• Understand data distributions\n• Compare groups\n\nLimitations:\n• Can be slow with many variables\n• May become crowded with >10 variables"),
    
    ("12. What is the purpose of the describe() function in Pandas?",
     "Answer:\ndescribe() generates descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset's distribution.\n\nStatistics returned:\n• count: Number of non-null values\n• mean: Arithmetic mean\n• std: Standard deviation\n• min: Minimum value\n• 25%: First quartile\n• 50%: Median (second quartile)\n• 75%: Third quartile\n• max: Maximum value\n\nExample:\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Age': [25, 30, 35, 40, 45, None],\n    'Salary': [50000, 60000, 70000, 80000, 90000, 100000]\n})\n\n# Basic statistics\nstats = df.describe()\n\n# Include categorical\ncat_stats = df.describe(include='all')\n\n# Specific percentiles\ncustom_stats = df.describe(percentiles=[.1, .5, .9])\n\nUse cases:\n• Quick data overview\n• Detect outliers\n• Identify missing values\n• Understand data distribution"),
    
    ("13. Why is handling missing data important in Pandas?",
     "Answer:\nHandling missing data is crucial because missing values can:\n\nProblems with missing data:\n1. Biased results: Can skew statistical analysis\n2. Reduced accuracy: ML models may underperform\n3. Errors: Some functions fail with NaN values\n4. Misleading conclusions: Incomplete data leads to wrong insights\n5. Wasted resources: Processing invalid data\n\nPandas methods for handling missing data:\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'A': [1, 2, np.nan, 4, 5],\n    'B': [np.nan, 2, 3, np.nan, 5]\n})\n\n# Detect missing\nprint(df.isnull().sum())\nprint(df.isna().any())\n\n# Remove missing\ndf_dropped = df.dropna()                    # Drop rows with any NaN\ndf_dropped_all = df.dropna(how='all')       # Drop rows where all are NaN\n\n# Fill missing\ndf_filled = df.fillna(0)                     # Fill with constant\ndf_ffill = df.fillna(method='ffill')         # Forward fill\ndf_mean = df.fillna(df.mean())                # Fill with mean\n\n# Interpolate\ndf_interp = df.interpolate()                  # Linear interpolation\n\nBest practices:\n• Understand why data is missing\n• Choose appropriate handling method\n• Document missing data decisions"),
    
    ("14. What are the benefits of using Plotly for data visualization?",
     "Answer:\nPlotly offers numerous benefits for data visualization:\n\n1. Interactivity: Hover tooltips, zoom, pan, selection\n2. Web-based: Easy sharing via HTML or Dash apps\n3. Multiple chart types: 30+ chart types including 3D\n4. Customization: Extensive styling options\n5. Real-time updates: Support for streaming data\n6. Language agnostic: R, Python, JavaScript support\n7. Publication quality: High-resolution exports\n8. Large datasets: Handles millions of points with WebGL\n9. Animation: Built-in animation support\n10. Subplots: Complex multi-plot layouts\n\nExample:\nimport plotly.express as px\n\n# Interactive scatter plot\nfig = px.scatter(df, x='x', y='y', color='category',\n                 hover_data=['info'], title='Interactive Plot')\nfig.show()\n\n# Save as HTML\nfig.write_html('plot.html')\n\nUse cases:\n• Exploratory data analysis\n• Dashboards and reports\n• Web applications\n• Presentations and demos\n• Collaborative analysis"),
    
    ("15. How does NumPy handle multidimensional arrays?",
     "Answer:\nNumPy handles multidimensional arrays through the ndarray (n-dimensional array) object, which provides efficient storage and operations on homogeneous data.\n\nKey concepts:\n\n1. Shape and dimensions:\nimport numpy as np\n\n# Create arrays\narr1d = np.array([1, 2, 3])                    # 1D, shape (3,)\narr2d = np.array([[1, 2], [3, 4]])             # 2D, shape (2, 2)\narr3d = np.random.rand(2, 3, 4)                # 3D, shape (2, 3, 4)\n\n# Access shape, dimensions, size\nprint(arr3d.shape)     # (2, 3, 4)\nprint(arr3d.ndim)      # 3\nprint(arr3d.size)      # 24\n\n2. Indexing and slicing:\n# Multi-dimensional indexing\narr = np.random.rand(3, 4)\nprint(arr[1, 2])                 # Single element\nprint(arr[1:3, :])               # Row slice, all columns\nprint(arr[:, [0, 2]])            # All rows, specific columns\n\n3. Reshaping:\narr = np.arange(12)\nreshaped = arr.reshape(3, 4)     # Reshape to 3×4\n\n4. Operations:\n# Axis operations\nrow_sum = arr.sum(axis=1)        # Sum along rows\ncol_mean = arr.mean(axis=0)       # Mean along columns\n\nNumPy's multidimensional arrays are memory-efficient and support advanced operations like broadcasting, vectorization, and linear algebra."),
    
    ("16. What is the role of Bokeh in data visualization?",
     "Answer:\nBokeh is a Python library for creating interactive visualizations for modern web browsers. It's designed for creating dashboards and data applications.\n\nKey features:\n\n1. Interactive plots: Zoom, pan, hover, selection\n2. Server integration: Real-time updates with Bokeh server\n3. Streaming data: Handle live data streams\n4. Complex layouts: Grid plots, tabs, widgets\n5. Export options: HTML, PNG, SVG\n6. Large datasets: Optimized for big data\n7. Custom JavaScript: Extend functionality\n\nExample:\nfrom bokeh.plotting import figure, show\nfrom bokeh.io import output_notebook\n\n# Create figure\np = figure(title='Interactive Plot', \n           x_axis_label='X', y_axis_label='Y')\n\n# Add glyphs\np.line(x, y, legend_label='Line', line_width=2)\n\n# Show plot\nshow(p)\n\nUse cases:\n• Web dashboards\n• Financial visualizations\n• Scientific applications\n• Real-time monitoring systems\n\nBokeh excels in creating web-ready, interactive visualizations with Python."),
    
    ("17. Explain the difference between apply() and map() in Pandas.",
     "Answer:\napply() and map() are used for element-wise operations but serve different purposes:\n\nmap():\n• Works only on Series (single column)\n• Can use dictionary or function for mapping\n• Good for simple transformations\n\napply():\n• Works on Series or DataFrames\n• More flexible, can use complex functions\n• Can operate along axes (row or column-wise)\n\nExamples:\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'Score': [85, 90, 95]\n})\n\n# map() - Series only\ndf['Grade'] = df['Score'].map({85: 'B', 90: 'A', 95: 'A+'})\n\n# apply() - Series\ndf['Age_category'] = df['Age'].apply(lambda x: 'Young' if x < 30 else 'Adult')\n\n# apply() - DataFrame (row-wise)\ndf['Average'] = df[['Age', 'Score']].apply(lambda x: (x[0] + x[1])/2, axis=1)\n\n# apply() - DataFrame (column-wise)\ndf_stats = df[['Age', 'Score']].apply(['mean', 'std'])\n\nKey difference:\n• map() is for simple value replacement/mapping\n• apply() is for complex transformations and aggregations"),
    
    ("18. What are some advanced features of NumPy?",
     "Answer:\nNumPy provides numerous advanced features for scientific computing:\n\n1. Linear Algebra:\nimport numpy as np\nfrom numpy.linalg import inv, eig, svd\n\nA = np.array([[1, 2], [3, 4]])\nA_inv = inv(A)                    # Matrix inverse\neigenvalues, eigenvectors = eig(A)  # Eigen decomposition\nU, s, V = svd(A)                  # SVD decomposition\n\n2. Fourier Transform:\nfft = np.fft.fft(signal)           # Fast Fourier transform\nfreq = np.fft.fftfreq(len(signal))\n\n3. Random Number Generation:\nrng = np.random.default_rng(seed=42)\nnorm = rng.normal(0, 1, 1000)      # Normal distribution\nchoice = rng.choice(arr, size=5)   # Random choice\n\n4. Advanced Indexing:\narr = np.array([[1, 2], [3, 4], [5, 6]])\nbool_idx = arr > 2                  # Boolean indexing\nrow_idx = arr[[0, 2]]               # Fancy indexing\n\n5. Broadcasting:\nresult = arr[:, np.newaxis] + arr   # Outer product\n\n6. Structured Arrays:\ndt = np.dtype([('name', 'U10'), ('age', 'i4')])\nstructured = np.array([('Alice', 25), ('Bob', 30)], dtype=dt)\n\n7. Universal Functions (ufunc):\nnp.add.reduce(arr)                  # Reduction operations\nnp.add.accumulate(arr)               # Accumulate operations\n\n8. Masked Arrays:\nmasked = np.ma.masked_where(arr < 0, arr)\n\n9. Polynomial Operations:\np = np.poly1d([1, 2, 3])            # x² + 2x + 3\nroots = p.roots\n\n10. Integration with C/C++:\n# Using Cython or ctypes for performance"),
    
    ("19. How does Pandas simplify time series analysis?",
     "Answer:\nPandas provides comprehensive tools for time series analysis:\n\n1. Datetime Index:\nimport pandas as pd\n\n# Create datetime index\ndates = pd.date_range('2023-01-01', periods=100, freq='D')\ndf = pd.DataFrame({'value': range(100)}, index=dates)\n\n2. Resampling:\n# Downsample to weekly\ndf_weekly = df.resample('W').mean()\n\n# Upsample to hourly\n# Various aggregation functions\n\n3. Date/Time Components:\ndf['year'] = df.index.year\ndf['month'] = df.index.month\ndf['day'] = df.index.day\ndf['dayofweek'] = df.index.dayofweek\n\n4. Shifting and Lagging:\ndf['shifted'] = df['value'].shift(1)      # Previous value\ndf['pct_change'] = df['value'].pct_change() # Percentage change\n\n5. Rolling Windows:\n# 7-day rolling average\ndf['rolling_avg'] = df['value'].rolling(window=7).mean()\n\n# Exponential moving average\ndf['ewm'] = df['value'].ewm(span=7).mean()\n\n6. Time Zone Handling:\ndf_utc = df.tz_localize('UTC')\ndf_est = df_utc.tz_convert('US/Eastern')\n\n7. Date Offsets:\nfrom pandas.tseries.offsets import BusinessDay\nnext_business = df.index + BusinessDay(1)\n\n8. Period Index:\nperiods = pd.period_range('2023-01', periods=12, freq='M')\n\n9. Specialized Functions:\n# Autocorrelation\ndf['value'].autocorr()\n\n# First valid index\ndf.first_valid_index()\n\n10. Time Series Plotting:\ndf.plot(figsize=(12, 6))"),
    
    ("20. What is the role of a pivot table in Pandas?",
     "Answer:\nA pivot table in Pandas is a data summarization tool that aggregates data based on multiple dimensions. It's similar to Excel pivot tables and allows flexible data transformation.\n\nKey components:\n• index: Row groupings\n• columns: Column groupings\n• values: Data to aggregate\n• aggfunc: Aggregation function\n\nExample:\nimport pandas as pd\n\n# Sample data\ndf = pd.DataFrame({\n    'Date': ['2023-01', '2023-01', '2023-02', '2023-02'],\n    'Region': ['North', 'South', 'North', 'South'],\n    'Product': ['A', 'A', 'B', 'B'],\n    'Sales': [100, 150, 200, 120]\n})\n\n# Basic pivot table\npivot = pd.pivot_table(\n    df,\n    values='Sales',\n    index='Region',\n    columns='Product',\n    aggfunc='sum'\n)\n\n# Multiple aggregations\npivot_multi = pd.pivot_table(\n    df,\n    values='Sales',\n    index=['Region', 'Date'],\n    aggfunc={'Sales': ['sum', 'mean', 'count']}\n)\n\n# With margins (totals)\npivot_totals = pd.pivot_table(\n    df,\n    values='Sales',\n    index='Region',\n    columns='Product',\n    aggfunc='sum',\n    margins=True,\n    margins_name='Total'\n)\n\nUse cases:\n• Sales reports by region and product\n• Customer segmentation analysis\n• Survey data summarization\n• Financial reporting\n\nBenefits:\n• Flexible multi-dimensional analysis\n• Easy data summarization\n• Quick insights generation"),
    
    ("21. Why is NumPy's array slicing faster than Python's list slicing?",
     "Answer:\nNumPy array slicing is faster due to several factors:\n\n1. Memory Layout:\n   • NumPy arrays store data in contiguous memory blocks\n   • Python lists store pointers to Python objects scattered in memory\n\n2. View vs Copy:\n   • NumPy slicing returns a view (no data copying)\n   • Python list slicing returns a new list (copies elements)\n\n3. C Implementation:\n   • NumPy operations are implemented in C\n   • Python lists require Python-level iteration\n\n4. Data Type Homogeneity:\n   • NumPy arrays have fixed data types\n   • Python lists store objects with type checking overhead\n\nPerformance comparison:\nimport numpy as np\nimport time\n\n# NumPy array\narr_np = np.arange(1_000_000)\n\n# Python list\nlist_py = list(range(1_000_000))\n\n# Time slicing\nstart = time.time()\nslice_np = arr_np[100000:200000]  # View, fast\nprint(f\"NumPy slice: {time.time() - start:.6f}s\")\n\nstart = time.time()\nslice_py = list_py[100000:200000]  # Copy, slower\nprint(f\"Python slice: {time.time() - start:.6f}s\")\n\n# Modifying slice affects original in NumPy\nslice_np[:] = 0  # Modifies original array too\n\nMemory efficiency:\n• NumPy slice shares data with original\n• Python slice creates independent copy\n\nThis makes NumPy ideal for large datasets where performance is critical."),
    
    ("22. What are some common use cases for Seaborn?",
     "Answer:\nSeaborn is widely used for statistical data visualization:\n\n1. Distribution Analysis:\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Histogram with KDE\nsns.histplot(data=df, x='value', kde=True)\n\n# Box plot for outliers\nsns.boxplot(data=df, x='category', y='value')\n\n# Violin plot (distribution + density)\nsns.violinplot(data=df, x='category', y='value')\n\n2. Relationship Analysis:\n# Scatter plot with regression line\nsns.regplot(data=df, x='x', y='y')\n\n# Pairplot for multiple variables\nsns.pairplot(data=df, hue='category')\n\n# Joint plot with marginal distributions\nsns.jointplot(data=df, x='x', y='y', kind='hex')\n\n3. Categorical Data:\n# Count plot\nsns.countplot(data=df, x='category')\n\n# Bar plot with confidence intervals\nsns.barplot(data=df, x='category', y='value')\n\n# Point plot for trends\nsns.pointplot(data=df, x='time', y='value', hue='group')\n\n4. Correlation Analysis:\n# Heatmap of correlations\ncorr = df.corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm')\n\n# Clustermap for hierarchical clustering\nsns.clustermap(corr)\n\n5. Time Series:\n# Line plot with confidence intervals\nsns.lineplot(data=df, x='date', y='value', hue='group')\n\n6. Model Diagnostics:\n# Residual plots\nsns.residplot(data=df, x='predicted', y='actual')\n\n7. Customization:\n# Set themes\nsns.set_theme(style='darkgrid')\n\n# Color palettes\nsns.color_palette('husl', 8)\n\n8. Advanced Plots:\n# Facet grids for multiple subplots\ng = sns.FacetGrid(df, col='category')\ng.map(sns.histplot, 'value')\n\nCommon industries:\n• Data Science: Exploratory analysis\n• Research: Publication-ready plots\n• Business: KPI dashboards\n• Education: Teaching statistics\n• Finance: Risk analysis\n• Healthcare: Patient data analysis")]
]
# 1. Create a 2D NumPy array and calculate the sum of each row
print("\\n" + "="*70)
print("Q1: 2D NumPy array and row sums")
print("="*70)

# Create 2D array
arr_2d = np.array([[1, 2, 3, 4],
                    [5, 6, 7, 8],
                    [9, 10, 11, 12]])

print("2D Array:")
print(arr_2d)
print(f"Shape: {arr_2d.shape}")

# Calculate sum of each row
row_sums = np.sum(arr_2d, axis=1)
print(f"\\nSum of each row: {row_sums}")

# Alternative methods
row_sums_alt = arr_2d.sum(axis=1)
print(f"Alternative method: {row_sums_alt}")

# 2. Pandas script to find the mean of a specific column
print("\\n" + "="*70)
print("Q2: Find mean of specific column in DataFrame")
print("="*70)

# Create DataFrame
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],
    'Age': [25, 30, 35, 28, 32],
    'Salary': [50000, 60000, 75000, 55000, 68000],
    'Experience': [2, 5, 8, 3, 6]
})

print("DataFrame:")
print(df)
print("\\n" + "-"*40)

# Find mean of Salary column
mean_salary = df['Salary'].mean()
print(f"Mean Salary: ${mean_salary:,.2f}")

# Multiple statistics
print(f"\\nSalary Statistics:")
print(f"  Mean: ${df['Salary'].mean():,.2f}")
print(f"  Median: ${df['Salary'].median():,.2f}")
print(f"  Std Dev: ${df['Salary'].std():,.2f}")
print(f"  Min: ${df['Salary'].min():,.2f}")
print(f"  Max: ${df['Salary'].max():,.2f}")

# 3. Create a scatter plot using Matplotlib
print("\\n" + "="*70)
print("Q3: Scatter plot with Matplotlib")
print("="*70)

# Generate sample data
np.random.seed(42)
x = np.random.randn(50)
y = 2 * x + np.random.randn(50) * 0.5
colors = np.random.rand(50)
sizes = np.random.randint(20, 200, 50)

# Create scatter plot
plt.figure(figsize=(10, 6))
scatter = plt.scatter(x, y, c=colors, s=sizes, alpha=0.7, cmap='viridis')
plt.colorbar(scatter, label='Color Value')
plt.xlabel('X Axis', fontsize=12)
plt.ylabel('Y Axis', fontsize=12)
plt.title('Scatter Plot with Matplotlib', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('scatter_plot.png', dpi=100)
plt.show()
print("Scatter plot created and saved as 'scatter_plot.png'")

# 4. Calculate correlation matrix and visualize with heatmap
print("\\n" + "="*70)
print("Q4: Correlation matrix with heatmap using Seaborn")
print("="*70)

# Create sample data with correlations
np.random.seed(42)
n_samples = 100
data = pd.DataFrame({
    'Feature_A': np.random.randn(n_samples),
    'Feature_B': np.random.randn(n_samples) * 0.5 + 2,
    'Feature_C': np.random.randn(n_samples) * 0.3 + 1,
    'Feature_D': np.random.randn(n_samples) * 0.8,
})

# Create correlations
data['Feature_E'] = data['Feature_A'] * 0.8 + np.random.randn(n_samples) * 0.2
data['Feature_F'] = -data['Feature_B'] * 0.7 + np.random.randn(n_samples) * 0.3

print("DataFrame shape:", data.shape)
print("\\nFirst few rows:")
print(data.head())

# Calculate correlation matrix
correlation_matrix = data.corr()
print("\\nCorrelation Matrix:")
print(correlation_matrix)

# Visualize with heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, 
            annot=True,           # Show values
            cmap='coolwarm',       # Color scheme
            center=0,              # Center colormap at 0
            square=True,           # Square cells
            linewidths=1,          # Line between cells
            cbar_kws={'shrink': 0.8},
            fmt='.2f')             # Format as 2 decimals
plt.title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=100)
plt.show()
print("Heatmap saved as 'correlation_heatmap.png'")

# 5. Generate a bar plot using Plotly
print("\\n" + "="*70)
print("Q5: Bar plot with Plotly")
print("="*70)

# Sample data for bar plot
categories = ['Product A', 'Product B', 'Product C', 'Product D', 'Product E']
sales_2023 = [45000, 62000, 38000, 71000, 53000]
sales_2024 = [52000, 68000, 42000, 79000, 61000]

# Create DataFrame for Plotly
df_bar = pd.DataFrame({
    'Product': categories * 2,
    'Sales': sales_2023 + sales_2024,
    'Year': ['2023'] * 5 + ['2024'] * 5
})

# Create interactive bar plot
fig = px.bar(df_bar, 
             x='Product', 
             y='Sales', 
             color='Year',
             title='Product Sales Comparison: 2023 vs 2024',
             barmode='group',
             text_auto='.2s',
             color_discrete_sequence=['#1f77b4', '#ff7f0e'])

fig.update_layout(
    xaxis_title='Product',
    yaxis_title='Sales ($)',
    font=dict(size=12),
    showlegend=True,
    hovermode='x'
)

fig.update_traces(textposition='outside')

# Show plot
fig.show()
print("Interactive bar plot created")
fig.write_html('bar_plot.html')
print("Saved as 'bar_plot.html'")

# 6. Create DataFrame and add new column based on existing column
print("\\n" + "="*70)
print("Q6: Add new column based on existing column")
print("="*70)

# Create base DataFrame
df_employees = pd.DataFrame({
    'Name': ['John', 'Sarah', 'Mike', 'Emma', 'David'],
    'Hours_Worked': [40, 45, 35, 50, 38],
    'Hourly_Rate': [25, 30, 28, 35, 22]
})

print("Original DataFrame:")
print(df_employees)

# Add new column based on existing columns
df_employees['Salary'] = df_employees['Hours_Worked'] * df_employees['Hourly_Rate']

# Add overtime indicator
df_employees['Overtime'] = df_employees['Hours_Worked'] > 40
df_employees['Overtime_Pay'] = np.where(
    df_employees['Hours_Worked'] > 40,
    (df_employees['Hours_Worked'] - 40) * df_employees['Hourly_Rate'] * 1.5,
    0
)

# Add performance category based on hours
conditions = [
    df_employees['Hours_Worked'] >= 45,
    df_employees['Hours_Worked'] >= 40,
    df_employees['Hours_Worked'] >= 30,
    df_employees['Hours_Worked'] < 30
]
choices = ['High Performer', 'Standard', 'Part Time', 'Low Hours']
df_employees['Performance'] = np.select(conditions, choices, default='Unknown')

print("\\nUpdated DataFrame with new columns:")
print(df_employees)

# 7. Element-wise multiplication of two NumPy arrays
print("\\n" + "="*70)
print("Q7: Element-wise multiplication of NumPy arrays")
print("="*70)

# Create two arrays
arr1 = np.array([1, 2, 3, 4, 5])
arr2 = np.array([10, 20, 30, 40, 50])

print(f"Array 1: {arr1}")
print(f"Array 2: {arr2}")

# Element-wise multiplication
result = arr1 * arr2
print(f"Element-wise multiplication: {result}")

# With 2D arrays
matrix1 = np.array([[1, 2], [3, 4]])
matrix2 = np.array([[5, 6], [7, 8]])

print("\\nMatrix 1:")
print(matrix1)
print("Matrix 2:")
print(matrix2)

element_wise = matrix1 * matrix2
print("Element-wise multiplication:")
print(element_wise)

# Different methods
print("\\nDifferent multiplication methods:")
print(f"np.multiply(arr1, arr2): {np.multiply(arr1, arr2)}")
print(f"arr1 * arr2: {arr1 * arr2}")

# 8. Line plot with multiple lines using Matplotlib
print("\\n" + "="*70)
print("Q8: Line plot with multiple lines using Matplotlib")
print("="*70)

# Generate time series data
np.random.seed(42)
time_points = np.arange(0, 10, 0.1)
series1 = np.sin(time_points) + np.random.normal(0, 0.1, len(time_points))
series2 = np.cos(time_points) + np.random.normal(0, 0.1, len(time_points))
series3 = np.sin(time_points * 1.5) + np.random.normal(0, 0.1, len(time_points))

# Create line plot
plt.figure(figsize=(12, 6))

plt.plot(time_points, series1, 'b-', label='Sine Wave', linewidth=2, alpha=0.8)
plt.plot(time_points, series2, 'r--', label='Cosine Wave', linewidth=2, alpha=0.8)
plt.plot(time_points, series3, 'g-.', label='Modified Sine', linewidth=2, alpha=0.8)

# Add shaded regions for confidence intervals
plt.fill_between(time_points, series1 - 0.2, series1 + 0.2, alpha=0.2, color='blue')
plt.fill_between(time_points, series2 - 0.2, series2 + 0.2, alpha=0.2, color='red')

plt.xlabel('Time (seconds)', fontsize=12)
plt.ylabel('Amplitude', fontsize=12)
plt.title('Multiple Time Series Plot', fontsize=14, fontweight='bold')
plt.legend(loc='upper right', fontsize=10)
plt.grid(True, alpha=0.3)
plt.xlim(0, 10)
plt.ylim(-2, 2)

# Add annotations
plt.annotate('Peak', xy=(1.5, 1.1), xytext=(2.5, 1.5),
             arrowprops=dict(facecolor='black', shrink=0.05, width=1.5))

plt.tight_layout()
plt.savefig('line_plot.png', dpi=100)
plt.show()
print("Line plot saved as 'line_plot.png'")

# 9. Filter rows where column value > threshold
print("\\n" + "="*70)
print("Q9: Filter DataFrame rows based on threshold")
print("="*70)

# Create larger DataFrame
np.random.seed(42)
df_large = pd.DataFrame({
    'ID': range(1, 21),
    'Value': np.random.randint(10, 100, 20),
    'Category': np.random.choice(['A', 'B', 'C'], 20),
    'Score': np.random.uniform(50, 100, 20).round(1)
})

print("Original DataFrame (first 10 rows):")
print(df_large.head(10))

# Filter rows where Value > 70
threshold = 70
filtered_df = df_large[df_large['Value'] > threshold]

print(f"\\nRows with Value > {threshold}:")
print(filtered_df)
print(f"Count: {len(filtered_df)} rows")

# Multiple conditions
filtered_multi = df_large[
    (df_large['Value'] > 50) & 
    (df_large['Category'] == 'A') &
    (df_large['Score'] > 75)
]

print("\\nRows with multiple conditions (Value>50, Category='A', Score>75):")
print(filtered_multi)

# Using query method
filtered_query = df_large.query('Value > 60 and Category == "B"')
print("\\nUsing query() method:")
print(filtered_query)

# 10. Create histogram using Seaborn
print("\\n" + "="*70)
print("Q10: Histogram with Seaborn")
print("="*70)

# Generate data with different distributions
np.random.seed(42)
data_hist = pd.DataFrame({
    'Normal': np.random.normal(100, 15, 1000),
    'Skewed': np.random.exponential(50, 1000),
    'Bimodal': np.concatenate([
        np.random.normal(70, 10, 500),
        np.random.normal(130, 10, 500)
    ])
})

# Create histogram
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Distribution Analysis with Histograms', fontsize=16, fontweight='bold')

# Normal distribution
sns.histplot(data_hist['Normal'], kde=True, ax=axes[0, 0], color='blue', bins=30)
axes[0, 0].set_title('Normal Distribution with KDE')
axes[0, 0].set_xlabel('Value')
axes[0, 0].set_ylabel('Frequency')

# Skewed distribution
sns.histplot(data_hist['Skewed'], kde=True, ax=axes[0, 1], color='red', bins=30)
axes[0, 1].set_title('Skewed Distribution')
axes[0, 1].set_xlabel('Value')

# Bimodal distribution
sns.histplot(data_hist['Bimodal'], kde=True, ax=axes[1, 0], color='green', bins=30)
axes[1, 0].set_title('Bimodal Distribution')
axes[1, 0].set_xlabel('Value')

# Overlay multiple distributions
for column, color in zip(['Normal', 'Skewed', 'Bimodal'], ['blue', 'red', 'green']):
    sns.kdeplot(data_hist[column], ax=axes[1, 1], color=color, label=column, linewidth=2)
axes[1, 1].set_title('KDE Comparison')
axes[1, 1].set_xlabel('Value')
axes[1, 1].legend()

plt.tight_layout()
plt.savefig('histograms.png', dpi=100)
plt.show()
print("Histograms saved as 'histograms.png'")

# 11. Matrix multiplication using NumPy
print("\\n" + "="*70)
print("Q11: Matrix multiplication with NumPy")
print("="*70)

# Create matrices
A = np.array([[1, 2, 3],
              [4, 5, 6]])

B = np.array([[7, 8],
              [9, 10],
              [11, 12]])

print("Matrix A (2×3):")
print(A)
print("\\nMatrix B (3×2):")
print(B)

# Matrix multiplication
C = np.dot(A, B)  # Method 1
print("\\nA @ B (2×2) using np.dot():")
print(C)

# Using @ operator (Python 3.5+)
C_alt = A @ B
print("\\nA @ B using @ operator:")
print(C_alt)

# For element-wise multiplication (Hadamard product)
# Need matrices of same shape
X = np.array([[1, 2], [3, 4]])
Y = np.array([[5, 6], [7, 8]])

print("\\nElement-wise multiplication (Hadamard product):")
print("X:")
print(X)
print("Y:")
print(Y)
print("X * Y:")
print(X * Y)

# 12. Load CSV file and display first 5 rows
print("\\n" + "="*70)
print("Q12: Load CSV and display first 5 rows")
print("="*70)

# Create sample CSV data
csv_data = '''Name,Age,Department,Salary,Hire_Date
John Smith,30,Engineering,85000,2020-03-15
Sarah Johnson,28,Marketing,72000,2021-06-01
Michael Brown,35,Engineering,95000,2019-11-20
Emily Davis,32,Sales,78000,2020-09-10
David Wilson,29,Engineering,82000,2022-01-05
Lisa Anderson,31,Marketing,71000,2021-08-15
Robert Taylor,38,Sales,88000,2018-04-22
Jennifer Lee,27,Engineering,79000,2022-03-01'''

# Write to CSV file
with open('employees.csv', 'w') as f:
    f.write(csv_data)

# Read CSV file
df_csv = pd.read_csv('employees.csv')

print("First 5 rows of the DataFrame:")
print(df_csv.head())

print("\\nDataFrame info:")
print(df_csv.info())

print("\\nBasic statistics:")
print(df_csv.describe())

# 13. Create 3D scatter plot using Plotly
print("\\n" + "="*70)
print("Q13: 3D Scatter plot with Plotly")
print("="*70)

# Generate 3D data
np.random.seed(42)
n_points = 100

df_3d = pd.DataFrame({
    'x': np.random.randn(n_points) * 2,
    'y': np.random.randn(n_points) * 2,
    'z': np.random.randn(n_points) * 2,
    'category': np.random.choice(['Group 1', 'Group 2', 'Group 3'], n_points),
    'size': np.random.uniform(5, 20, n_points),
    'intensity': np.random.rand(n_points)
})

# Create 3D scatter plot
fig = px.scatter_3d(df_3d, 
                    x='x', 
                    y='y', 
                    z='z',
                    color='category',
                    size='size',
                    hover_data=['intensity'],
                    title='3D Scatter Plot with Groups',
                    labels={'x': 'X Axis', 'y': 'Y Axis', 'z': 'Z Axis'},
                    color_discrete_sequence=px.colors.qualitative.Set1)

# Update layout for better visualization
fig.update_layout(
    scene=dict(
        xaxis_title='X Dimension',
        yaxis_title='Y Dimension',
        zaxis_title='Z Dimension',
        camera=dict(
            eye=dict(x=1.5, y=1.5, z=1.5)
        )
    ),
    legend_title='Categories',
    font=dict(size=12),
    width=800,
    height=600
)

# Show plot
fig.show()
print("Interactive 3D scatter plot created")
fig.write_html('scatter_3d.html')
print("Saved as 'scatter_3d.html'")

# Bonus: Combined visualization example
print("\\n" + "="*70)
print("BONUS: Comprehensive Data Analysis Example")
print("="*70)

# Load built-in dataset
iris = sns.load_dataset('iris')
print("Iris dataset loaded")
print(iris.head())

# Create comprehensive visualization
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
fig.suptitle('Comprehensive Iris Dataset Analysis', fontsize=16, fontweight='bold')

# 1. Scatter plot
sns.scatterplot(data=iris, x='sepal_length', y='sepal_width', 
                hue='species', ax=axes[0, 0])
axes[0, 0].set_title('Sepal Dimensions')

# 2. Box plot
sns.boxplot(data=iris, x='species', y='petal_length', ax=axes[0, 1])
axes[0, 1].set_title('Petal Length by Species')

# 3. Violin plot
sns.violinplot(data=iris, x='species', y='petal_width', ax=axes[0, 2])
axes[0, 2].set_title('Petal Width Distribution')

# 4. Histogram
sns.histplot(data=iris, x='sepal_length', hue='species', 
             multiple='stack', ax=axes[1, 0])
axes[1, 0].set_title('Sepal Length Distribution')

# 5. Correlation heatmap
numeric_cols = iris.select_dtypes(include=[np.number])
sns.heatmap(numeric_cols.corr(), annot=True, cmap='coolwarm', 
            ax=axes[1, 1], fmt='.2f')
axes[1, 1].set_title('Feature Correlations')

# 6. Pairwise relationship
sns.scatterplot(data=iris, x='petal_length', y='petal_width', 
                hue='species', size='sepal_length', 
                sizes=(20, 200), ax=axes[1, 2])
axes[1, 2].set_title('Petal: Length vs Width')

plt.tight_layout()
plt.savefig('iris_analysis.png', dpi=100)
plt.show()
print("Comprehensive analysis plot saved as 'iris_analysis.png'")

print("\\n" + "="*70)
print("ALL PRACTICAL QUESTIONS COMPLETED")
print("="*70)
'''
